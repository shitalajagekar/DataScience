{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>a2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>a3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>a4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>a5.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    path\n",
       "0      0  a1.jpg\n",
       "1      0  a2.jpg\n",
       "2      0  a3.jpg\n",
       "3      0  a4.jpg\n",
       "4      0  a5.jpg"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x216b406a1d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "img = mpimg.imread('images/a1.jpg')\n",
    "\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = df[\"path\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = []\n",
    "for image_name in image_path:\n",
    "    img = image.load_img('images/'+image_name, target_size=(28,28,1), grayscale=True)\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255 # Normalization\n",
    "    train_image.append(img)\n",
    "X = np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(26, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 133 samples, validate on 34 samples\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.3525 - accuracy: 0.8947 - val_loss: 6.9196 - val_accuracy: 0.1176\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.3549 - accuracy: 0.9023 - val_loss: 6.9394 - val_accuracy: 0.1176\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.2624 - accuracy: 0.9624 - val_loss: 6.9548 - val_accuracy: 0.1471\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.3070 - accuracy: 0.9248 - val_loss: 6.9882 - val_accuracy: 0.1471\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.3275 - accuracy: 0.9248 - val_loss: 7.0202 - val_accuracy: 0.1176\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.1951 - accuracy: 0.9474 - val_loss: 7.1076 - val_accuracy: 0.1176\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.2095 - accuracy: 0.9549 - val_loss: 7.2585 - val_accuracy: 0.0882\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.1496 - accuracy: 0.9774 - val_loss: 7.3438 - val_accuracy: 0.0882\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.1425 - accuracy: 0.9549 - val_loss: 7.5438 - val_accuracy: 0.0882\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.2128 - accuracy: 0.9474 - val_loss: 7.7910 - val_accuracy: 0.0882\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.2538 - accuracy: 0.9323 - val_loss: 7.9430 - val_accuracy: 0.0882\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.2246 - accuracy: 0.9248 - val_loss: 8.0143 - val_accuracy: 0.0882\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.2179 - accuracy: 0.9323 - val_loss: 7.9137 - val_accuracy: 0.0882\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.3110 - accuracy: 0.9173 - val_loss: 7.6443 - val_accuracy: 0.1176\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.1596 - accuracy: 0.9850 - val_loss: 7.5062 - val_accuracy: 0.1176\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.2523 - accuracy: 0.9474 - val_loss: 7.5626 - val_accuracy: 0.1176\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.1265 - accuracy: 0.9774 - val_loss: 7.7333 - val_accuracy: 0.1176\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.1106 - accuracy: 0.9549 - val_loss: 7.9048 - val_accuracy: 0.1176\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.1537 - accuracy: 0.9774 - val_loss: 8.0196 - val_accuracy: 0.1176\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.1184 - accuracy: 0.9925 - val_loss: 8.1226 - val_accuracy: 0.1176\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.1111 - accuracy: 0.9624 - val_loss: 8.0421 - val_accuracy: 0.1176\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.1616 - accuracy: 0.9624 - val_loss: 8.0436 - val_accuracy: 0.1176\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.0930 - accuracy: 0.9850 - val_loss: 8.3221 - val_accuracy: 0.1176\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.1528 - accuracy: 0.9549 - val_loss: 8.3837 - val_accuracy: 0.1176\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.1089 - accuracy: 0.9925 - val_loss: 8.6471 - val_accuracy: 0.1176\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.0584 - accuracy: 1.0000 - val_loss: 8.9530 - val_accuracy: 0.1176\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.0646 - accuracy: 0.9850 - val_loss: 9.2302 - val_accuracy: 0.1176\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.1053 - accuracy: 0.9699 - val_loss: 9.4881 - val_accuracy: 0.1176\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.0887 - accuracy: 0.9624 - val_loss: 9.5209 - val_accuracy: 0.1176\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 3ms/sample - loss: 0.1206 - accuracy: 0.9699 - val_loss: 9.3190 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x216b5c75908>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = image.load_img('images/'+\"d7.jpg\", target_size=(28,28,1), grayscale=True)\n",
    "img = image.img_to_array(img)\n",
    "img = img/255\n",
    "model.predict_classes([[img]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
